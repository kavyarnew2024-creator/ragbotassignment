import streamlit as st
import os
from dotenv import load_dotenv
from langchain_community.document_loaders.pdf import PyPDFLoader
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.chains.conversational_retrieval.base import ConversationalRetrievalChain
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.prompts import PromptTemplate

# Load environment variables
load_dotenv()

# Streamlit page setup
st.set_page_config(page_title="üìò Class 6 English Chatbot")

st.title("üìò Class 6 English Textbook Chatbot")
st.write("Ask questions from your 6th standard English book")

# --------- CREATE RAG ONLY ONCE ----------
@st.cache_resource
def create_rag_chatbot():
    # 1. Load PDF
    loader = PyPDFLoader("class6_english.pdf")
    documents = loader.load()

    # 2. Split text into chunks
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,
        chunk_overlap=50
    )
    chunks = splitter.split_documents(documents)

    # 3. Convert text to embeddings
    embeddings = OpenAIEmbeddings()

    # 4. Store embeddings in FAISS vector DB
    vector_db = FAISS.from_documents(chunks, embeddings)

    # 5. Create retriever
    retriever = vector_db.as_retriever()

    # 6. Corrective RAG Prompt
    corrective_prompt = PromptTemplate(
        template="""
You are a kind English teacher for a 6th standard student.

Rules you MUST follow:
1. Answer ONLY using the textbook content given in context.
2. If the answer is not found, say:
   "This answer is not available in your textbook."
3. Use simple English.
4. Keep answers short and clear.
5. Remember previous questions in this conversation.

Context:
{context}

Chat History:
{chat_history}

Question:
{question}

Answer:
""",
        input_variables=["context", "chat_history", "question"]
    )

    # 7. LLM (No hallucination)
    llm = ChatOpenAI(
        model="gpt-3.5-turbo",
        temperature=0
    )

    # 8. RAG chain with memory
    rag_chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=retriever,
        combine_docs_chain_kwargs={"prompt": corrective_prompt}
    )

    return rag_chain

# Initialize chatbot
if "rag_chain" not in st.session_state:
    st.session_state.rag_chain = create_rag_chatbot()

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# --------- USER INPUT ----------
question = st.text_input("‚úèÔ∏è Ask your question")

if st.button("Ask"):
    if question.strip() != "":
        result = st.session_state.rag_chain({
            "question": question,
            "chat_history": st.session_state.chat_history
        })

        answer = result["answer"]

        st.session_state.chat_history.append((question, answer))

        st.success(answer)

# --------- SHOW CHAT HISTORY ----------
st.write("### üìú Chat History")
for q, a in st.session_state.chat_history:
    st.write(f"**You:** {q}")
    st.write(f"**Bot:** {a}")











